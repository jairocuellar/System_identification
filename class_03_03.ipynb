{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0682a7",
   "metadata": {},
   "source": [
    "# IDENTIFICACIÓN DE SISTEMAS\n",
    "\n",
    "Profesor: Jairo Alberto Cuéllar Guarnizo  \n",
    "Programa: Ingeniería en Automatización y Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f44449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import MatrixSymbol, Matrix, Identity\n",
    "\n",
    "import sympy as sym\n",
    "import pandas as pd\n",
    "\n",
    "sym.init_printing()\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import control\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb0f3c",
   "metadata": {},
   "source": [
    "# Métodos paramétricos de estimación\n",
    "\n",
    "## Estimación Lineal por mínimos cuadráticos (LS)\n",
    "\n",
    "Técnica para ayudar a encontrar modelos lineales que se representan como algún parámetro desconocido $\\theta$ (Estimador). Recordar que y(1), ... , y(N) son mediciones de la función que queremos estimar (variables dependientes). Existe otra secuencia denominada el vector de regresión $\\phi(0), ... ,\\phi(N)$, las cuales se reconocen como las entradas del modelo o variables independientes (vector de regresión). Un modelo lineal de predicción que incluye errores está dado por la siguiente relación:\n",
    "\n",
    "$$y(k) = \\phi(k)^T\\theta + \\varepsilon(k)$$\n",
    "\n",
    "Inicialmente consideremos el error como 0, $y(k) = \\phi(k)^T\\theta$. La idea de LLS es minimizar el valor de error entre las mediciones $y(k)$ y sus valores estimados $\\theta$ elevados al cuadrado, por tanto la función de costo a minimizar sería:\n",
    "\n",
    "$$\\sum_{k=1}^{N}(y(k)-\\phi(k)^T\\theta)^2$$\n",
    "\n",
    "Asumamos $y[k]$ como $y$, $\\phi(k)$ como $\\phi$. El estimador $\\theta$ es el valor que minimiza la función de costo.\n",
    "\n",
    "Matricialmente la expresión de la función de costo que llamaremos $f(\\theta)$ será:\n",
    "\n",
    "$$f(\\theta) = \\frac{1}{2}|y - \\phi\\theta|^2$$\n",
    "\n",
    "Omitiendo los subindices N y la notación vectorial, esta ecuación matricial se puede minimizar y evaluar mediante el cálculo del gradiente y la matriz Hessiana.\n",
    "\n",
    "$$f(\\theta) = \\frac{1}{2}|y^T.y - 2.\\phi^T.y.\\theta + \\phi^T.\\phi.\\theta^2|$$\n",
    "\n",
    "Calculando el gradiende tendríamos:\n",
    "\n",
    "$$\\bigtriangledown f(\\theta) = \\bigtriangledown(\\frac{1}{2}|y^T.y - 2.\\phi^T.y.\\theta + \\phi^T.\\phi.\\theta^2|) = - \\phi^T.y + \\phi^T.\\phi.\\theta = 0$$\n",
    "\n",
    "Despejando el estimador:\n",
    "\n",
    "$$\\theta = (\\phi^T.\\phi)^{-1}.\\phi^T.y$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71284ffe",
   "metadata": {},
   "source": [
    "## Ejemplo 1 (LS) - Vector de regresión unitario\n",
    "\n",
    "Asumamos un modelo constante con las siguientes condiciones:\n",
    "\n",
    "$$y(k) = \\phi(k)^T\\theta + \\varepsilon(k)$$\n",
    "\n",
    "Si $\\phi$ es unitario el modelo se reduce a:\n",
    "\n",
    "$$y(k) = \\theta + \\varepsilon(k)$$\n",
    "\n",
    "Ahora se debe encontrar el mejor estimador $\\theta$ teniendo en cuenta lo siguiente:\n",
    "\n",
    "$y = \\begin{bmatrix}y(1)\\\\y(2)\\\\...\\\\y(N)\\end{bmatrix}$, Según el modelo asumido, el vector de regresión estaría dado por: $\\phi = \\begin{bmatrix}1\\\\1\\\\...\\\\1\\end{bmatrix}$. Las dimensiones de estos vectores es de Nx1.\n",
    "\n",
    "Es relativamente sencillo calcular el mejor estimador usando la relación obtenida anteriormente:\n",
    "\n",
    "$$\\theta = (\\phi^T.\\phi)^{-1}.\\phi^T.y$$\n",
    "\n",
    "$$\\phi^T.\\phi = \\begin{bmatrix}1&1&...&1\\end{bmatrix}\\begin{bmatrix}1\\\\1\\\\...\\\\1\\end{bmatrix} = N$$\n",
    "\n",
    "Y por consiguiente:\n",
    "\n",
    "$$(\\phi^T.\\phi)^{-1}=\\frac{1}{N}$$\n",
    "\n",
    "Ahora observemos la expresión:\n",
    "$$\\phi^T.y = \\begin{bmatrix}1&1&...&1\\end{bmatrix}\\begin{bmatrix}y(1)\\\\y(2)\\\\...\\\\y(N)\\end{bmatrix} = \\sum_{k=1}^{N}y(k)$$\n",
    "\n",
    "Entonces armando el estimador, se tiene que con un vector de regresión unitario, el modelo estimado es un promedio:\n",
    "\n",
    "$$\\theta = \\frac{1}{N}\\sum_{k=1}^{N}y(k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2acee7e",
   "metadata": {},
   "source": [
    "## Ejemplo 2 (LS) - Estimación de resistencia por LS\n",
    "\n",
    "Asumamos un modelo constante con las siguientes condiciones: $y(k) = V(k)$, $\\phi(k) = I(k)$, $\\theta = R$.\n",
    "\n",
    "Asumiendo que el mejor estimador es el siguiente:\n",
    "\n",
    "$$\\theta = (\\phi^T.\\phi)^{-1}.\\phi^T.y$$\n",
    "\n",
    "$$\\phi^T.\\phi = \\begin{bmatrix}I(1)&I(2)&...&I(N)\\end{bmatrix}\\begin{bmatrix}I(1)\\\\I(2)\\\\...\\\\I(N)\\end{bmatrix} = \\sum_{k=1}^{N}I(k)^2$$\n",
    "\n",
    "Por tanto el inverso de esta expresión sería:\n",
    "\n",
    "$$(\\phi^T.\\phi)^{-1} = \\frac{1}{\\sum_{k=1}^{N}I(k)^2}$$\n",
    "\n",
    "Por último se tiene que \n",
    "\n",
    "$$\\phi^T.y = \\begin{bmatrix}I(1)&I(2)&...&I(N)\\end{bmatrix}\\begin{bmatrix}V(1)\\\\V(2)\\\\...\\\\V(N)\\end{bmatrix} = \\sum_{k=1}^{N}I(k)V(k)$$\n",
    "\n",
    "Finalmente:\n",
    "\n",
    "$$\\theta = \\frac{\\frac{1}{N}\\sum_{k=1}^{N}I(k)V(k)}{\\frac{1}{N}\\sum_{k=1}^{N}I(k)^2}$$\n",
    "\n",
    "Modelo previamente obtenido en las clases anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4878e3",
   "metadata": {},
   "source": [
    "## Ejemplo 3 (LS) - Estimación asumiendo un modelo lineal\n",
    "\n",
    "Asumamos un modelo lineal con las siguientes condiciones: $y(k) = \\theta_1 + \\theta_2.x(k)$.\n",
    "\n",
    "Asumiendo que el mejor estimador es el siguiente:\n",
    "\n",
    "$$\\theta = (\\phi^T.\\phi)^{-1}.\\phi^T.y$$\n",
    "\n",
    "Y donde el vector de estimador debería tener la siguiente forma, según el modelo esperado:\n",
    "\n",
    "$$\\phi = \\begin{bmatrix}1 & x(1)\\\\1 & x(2)\\\\...&...\\\\1 & x(N)\\end{bmatrix}$$\n",
    "\n",
    "Se espera que en este caso el vector de estimación sea:\n",
    "\n",
    "$$\\theta = \\begin{bmatrix}\\theta_1\\\\\\theta_2\\end{bmatrix}$$\n",
    "\n",
    "Por último se tiene que \n",
    "\n",
    "$$\\phi^T.\\phi = \\begin{bmatrix}x(1)&x(2)&...&x(N)\\\\1&1&...&1\\end{bmatrix}\\begin{bmatrix}1 & x(1)\\\\1 & x(2)\\\\...&...\\\\1 & x(N)\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\sum_{k=1}^{N}x(n)&\\sum_{k=1}^{N}x(n)^2\\\\N&\\sum_{k=1}^{N}x(n) \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "El cálculo de la inversa de $\\phi^T.\\phi$, puede realizarse con la utilización de software apropiado. Finalmente la expresión:\n",
    "\n",
    "$$\\phi^T.y = \\begin{bmatrix}x(1)&x(2)&...&x(N)\\\\1&1&...&1\\end{bmatrix}\\begin{bmatrix}y(1)\\\\y(2)\\\\...\\\\y(N)\\end{bmatrix}=\\begin{bmatrix}\\sum_{k=1}^{N}x(n)y(n)\\\\\\sum_{k=1}^{N}y(n)\\end{bmatrix} $$\n",
    "\n",
    "Por último el vector de estimaciones sería:\n",
    "\n",
    "$$\\theta = \\begin{bmatrix}\\theta_1\\\\\\theta_2\\end{bmatrix}=(\\phi^T.\\phi)^{-1}.\\phi^T.y = \\begin{bmatrix}\n",
    "\\sum_{k=1}^{N}x(n)&\\sum_{k=1}^{N}x(n)^2\\\\N&\\sum_{k=1}^{N}x(n) \n",
    "\\end{bmatrix}^{-1}\\begin{bmatrix}\\sum_{k=1}^{N}x(n)y(n)\\\\\\sum_{k=1}^{N}y(n)\\end{bmatrix}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
