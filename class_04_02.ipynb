{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0682a7",
   "metadata": {},
   "source": [
    "# IDENTIFICACIÓN DE SISTEMAS\n",
    "\n",
    "Profesor: Jairo Alberto Cuéllar Guarnizo  \n",
    "Programa: Ingeniería en Automatización y Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59f44449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import MatrixSymbol, Matrix, Identity\n",
    "\n",
    "import sympy as sym\n",
    "import pandas as pd\n",
    "\n",
    "sym.init_printing()\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import control\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb0f3c",
   "metadata": {},
   "source": [
    "# Métodos paramétricos de estimación\n",
    "\n",
    "## Estimación Lineal por mínimos cuadráticos (LS) - Resumen\n",
    "\n",
    "Para el siguiente modelo lineal:\n",
    "\n",
    "$$y[k] = \\phi[k]^T\\theta + \\varepsilon[k]$$\n",
    "\n",
    "Inicialmente consideremos el error como 0, por tanto el modelo se reduce a $y[k] = \\phi[k]^T\\theta$. La idea de LLS es minimizar el valor de error entre las mediciones $y[k]$ y los valores estimados $\\theta$ elevados al cuadrado, por tanto la función de costo a minimizar sería:\n",
    "\n",
    "$$f(\\theta) = \\frac{1}{2}|y - \\phi\\theta|^2$$\n",
    "\n",
    "En la sección anterior se llegó a la conclusión que el vector de parámetros estimados es equivalente a:\n",
    "\n",
    "$$\\theta = [\\phi^T.\\phi]^{-1}.\\phi^T.y$$\n",
    "\n",
    "$$\\theta_{LS} = \\phi^+.y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6845a2",
   "metadata": {},
   "source": [
    "## Estimación Lineal por mínimos cuadráticos con pesos (WLS)\n",
    "\n",
    "Considerando que la señal del error es de media cero, pero que contiene varianzas distintas, se podría evaluar la siguiente función de costos, que considera que ante cada medición se divide en la varianza de dicha medición. Por tanto la función de costo no tendría unidades:\n",
    "\n",
    "$$f_{WLS}(\\theta) = \\sum_{k=1}^{N}\\frac{(y[k]-\\phi^T.\\theta)^2}{\\sigma_{\\epsilon}[k]^2}$$\n",
    "\n",
    "En este caso, se puede introducir una matriz de pesos, denominada W y que estaría dada por la siguiente relación:\n",
    "\n",
    "$$W = \\begin{bmatrix}\\sigma_{\\epsilon}[1]^{-2}& & \\\\ & ... & \\\\ & &\\sigma_{\\epsilon}[N]^{-2}\\end{bmatrix}$$\n",
    "\n",
    "Se podría reescribir la función de costo de forma vectorial así:\n",
    "\n",
    "$$f_{WLS}(\\theta) = |y-\\phi.\\theta|^2.W$$\n",
    "\n",
    "$$f_{WLS}(\\theta) = (y-\\phi.\\theta)^T.W.(y-\\phi.\\theta)$$\n",
    "\n",
    "Calculando el gradiente en función de teta y despejando el estimador se obtiene la siguiente relación:\n",
    "\n",
    "$$\\theta_{WLS} = (\\phi^T.W.\\phi)^{-1}.\\phi^T.W.y$$\n",
    "\n",
    "Otra forma de obtener el vector de los parámetros estimados es introducir la matriz $W^{1/2}$, que es equivalente a la raiz cuadrada de la matriz de pesos W.\n",
    "\n",
    "$$W^{1/2} = \\begin{bmatrix}\\sigma_{\\epsilon}[1]^{-1}& & \\\\ & ... & \\\\ & &\\sigma_{\\epsilon}[N]^{-1}\\end{bmatrix}$$\n",
    "\n",
    "Tal que: $W = W^{1/2}.W^{1/2}$\n",
    "\n",
    "Sustituyendo en la función de costo se tiene lo siguiente:\n",
    "\n",
    "$$f_{WLS}(\\theta) = |W^{1/2}.(y-\\phi.\\theta)|^2 = |W^{1/2}.y-W^{1/2}.\\phi.\\theta)|^2 $$\n",
    "\n",
    "Se introducen dos nuevos vectores como se indica a continuación para el vector normalizados de regresión y para los valores medidos normalizados:\n",
    "\n",
    "$$\\tilde{y} = W^{1/2}.y$$\n",
    "\n",
    "$$\\tilde{\\phi} = W^{1/2}.\\phi$$\n",
    "\n",
    "Aplicando los criterios de optimalidad a esta función de costo y despejando el estimador y teniendo en cuenta las 2 relaciones anteriores se podría indicar que el vector de parámetros estimados daría:\n",
    "\n",
    "$$\\theta_{WLS} = [\\tilde{\\phi}^T.\\tilde{\\phi}]^{-1}.\\tilde{\\phi}^T.\\tilde{y}$$\n",
    "\n",
    "$$\\theta_{WLS} = \\tilde{\\phi}^+.\\tilde{y}$$\n",
    "\n",
    "Así que un problema de mínimos cuadrados con pesos, es solo un problema de mínimos cuadrados escalando la matriz de regresión y los valores medidos por la matriz $W^{1/2}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdb4539f",
   "metadata": {},
   "source": [
    "## Ejemplo 1:\n",
    "\n",
    "Se espera poder determinar un modelo lineal dado por: $y = -6 + 2x$. Además, se tiene un vector de mediciones de longitud 5, dado por la siguiente relación:\n",
    "$$y[k] = \\begin{bmatrix}y[1]\\\\y[2]\\\\...\\\\y[N]\\end{bmatrix}=\\begin{bmatrix}-5.996\\\\-4.008\\\\-1.997\\\\-0.009 \\\\ 2.009\\end{bmatrix}$$.\n",
    "\n",
    "Considere a su vez que x está de 0 a 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6ea6fde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), array([-5.998, -4.005, -1.998, -0.008,  2.002]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Valores de x = 0, 1, 2, 3, 4\n",
    "x = np.linspace(0,4,5,dtype = \"int\")\n",
    "\n",
    "#Valores medidos con un error y\n",
    "y = np.array([-5.998,-4.005,-1.998,-0.008,2.002])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf0c58",
   "metadata": {},
   "source": [
    "La matriz de regresión, al ser un modelo lineal estaría dada por: $\\phi = \\begin{bmatrix}1 & x[1]\\\\1 & x[2]\\\\1 & x[3]\\\\1 & x[4]\\\\1 & x[5]\\end{bmatrix}$. \n",
    "\n",
    "Y se debe considerar las covarianzas dadas por:\n",
    "\n",
    "$W = \\begin{bmatrix}0.063&0&0&0&0\\\\0&0.062&0&0&0\\\\0&0&0.25&0&0\\\\0&0&0&12345&0\\\\0&0&0&0&0.248\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b14a62c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.3000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 6.2000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 2.5100e-01, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5625e+04, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e-01]]),\n",
       " array([[  0.25099801,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [  0.        ,   0.24899799,   0.        ,   0.        ,\n",
       "           0.        ],\n",
       "        [  0.        ,   0.        ,   0.500999  ,   0.        ,\n",
       "           0.        ],\n",
       "        [  0.        ,   0.        ,   0.        , 125.        ,\n",
       "           0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.5       ]]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La matriz de regresión considerando el modelo lineal\n",
    "ones = np.ones(N)\n",
    "phi = np.array([ones,x]).transpose()\n",
    "\n",
    "# Varianzas para cada xk\n",
    "var = np.array([0.063,0.062,0.251,15625,0.25])\n",
    "_var = var**0.5\n",
    "\n",
    "## Matriz de pesos (Covarianzas)\n",
    "W = np.eye(N)*var\n",
    "_W = np.eye(N)*_var\n",
    "W,    _W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de5996",
   "metadata": {},
   "source": [
    "Se debe calcular los vectores normalizados \n",
    "$$\\tilde{y} = W^{1/2}.y$$\n",
    "\n",
    "$$\\tilde{\\phi} = W^{1/2}.\\phi$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "07f0de16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.50548605, -0.99723696, -1.00099601, -1.        ,  1.001     ]),\n",
       " array([[2.50998008e-01, 0.00000000e+00],\n",
       "        [2.48997992e-01, 2.48997992e-01],\n",
       "        [5.00999002e-01, 1.00199800e+00],\n",
       "        [1.25000000e+02, 3.75000000e+02],\n",
       "        [5.00000000e-01, 2.00000000e+00]]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vectores \"y\" y \"phi\" Normalizados usando W\n",
    "_y = np.dot(_W,y)\n",
    "_phi = np.dot(_W,phi)\n",
    "_y,      _phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2450b8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.00282057,  1.99827364])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculando los estimados THETA\n",
    "phi_pr = np.dot(_phi.transpose(),_phi)\n",
    "A = np.linalg.inv(phi_pr)\n",
    "B = np.dot(_phi.transpose(),_y)\n",
    "\n",
    "## Vector de parámetros estimados\n",
    "theta = np.dot(A,B)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd82c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
